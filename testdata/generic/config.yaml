data_generation:
  cache: # str, Give folder name to use caching of the data
  train_batch_size: 2 # int, batch size for training
  valid_batch_size: 2 # int, batch size for validation 
  drop_cases: # list of lists
    # - ['value_to_drop', 'internal_column_name'] if cases should be dropped based on target label (e.g. label -1)
    # - ['value_to_drop', 'annotation_column'] if cases should be dropped based on additional column (e.g. age 0)
    - ['-1', 'isup']
  resize: &resize 256 # int, needs to be according to the Inception-v3 model that is used
  seed: 161 # int, definition of a seed to make results reproducible

# ------  ------  ------  ------  ------  ------  ------

model:
  additional_input: # list, column names of additional inputs
  dense_layer_nodes: [32] # list, number of nodes for dense layer
  rnn_layer_nodes: # list, number of nodes for rnn layers
  keras_model_params: # dict, infos for keras model
    weights: imagenet # None or 'imagenet'
    input_shape: [*resize, *resize, 3]
  cut_off_layer: 'mixed4_base' # str, layer where Inception-v3 is cut off to add eCaReNet layers

# ------  ------  ------  ------  ------  ------  ------

training:
  epochs: 3 # int, how many epochs to train (number of communications)
  local_epochs: 1 # int, how many epochs to train per communucation round (before merging models again)
  monitor_val: 'val_tf_categorical_accuracy' # str, metric that is used to determine best epoch
  callbacks: # dict, new callbacks like lr scheduler or early stopping can be defined
  optimizer: # dict
    name: SGD # str, tf.keras optimizer, e.g. 'Adam', 'Nadam'
    params: # list of additional parameters as dict
      - learning_rate: 0.005
  loss_fn: isup_cce_loss # str, loss function for the optimizer
  compile_metrics: # list, metrics for the optimizer
    - TfCategoricalAccuracy
  compile_attributes: {} # dict, additional attributes 
  class_weight: True # bool, weighting classes by occurrence
  weighted_metrics: False # bool, using weighted metrics
  aggregation_method: fed_avg # str, defines which aggregation method to use

# ------  ------  ------  ------  ------  ------  ------

evaluation:
  metrics: # list, lists the metrics to evaluate the test dataset 
    - accuracy
    - f1_score
    - kappa